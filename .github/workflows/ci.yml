name: MLC-LLM CI/CD

on:
  push:
    branches: [main]
    tags: [ 'v*.*.*' ]
  pull_request:
    branches: [main]
  workflow_dispatch:

permissions:
  contents: write

jobs:

  docker-build:
    name: ✨ Build & Push Docker Image
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: docker/setup-qemu-action@v3
      - uses: docker/setup-buildx-action@v3
      - uses: docker/login-action@v3
        with:
          registry: ghcr.io
          username: ${{ github.actor }}
          password: ${{ secrets.GHCR_PAT }}
      - uses: docker/build-push-action@v5
        with:
          context: .
          file: docker/Dockerfile
          push: true
          tags: ghcr.io/${{ github.repository }}:latest
          platforms: linux/amd64

  test:
    name: ✅ Run Tests in Docker
    runs-on: ubuntu-latest
    needs: docker-build
    steps:
      - uses: actions/checkout@v4
      - run: echo "${{ secrets.GHCR_PAT }}" | docker login ghcr.io -u ${{ github.actor }} --password-stdin
      - run: |
          docker run --rm --gpus all \
            -e CI=true \
            -v ${{ github.workspace }}:/workspace \
            -w /workspace \
            ghcr.io/${{ github.repository }}:latest \
            ./scripts/test-image.sh

  build-wheels:
    name: 🏋️ Build Python Wheels
    runs-on: ${{ matrix.os }}
    needs: test
    strategy:
      matrix:
        os: [ubuntu-latest, windows-latest, macos-latest]
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with:
          python-version: '3.10'
      - uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}
      - run: pip install build
      - run: python -m build python/
      - uses: actions/upload-artifact@v4
        with:
          name: wheel-${{ matrix.os }}
          path: python/dist/*.whl

  release:
    name: 📦 GitHub Release
    runs-on: ubuntu-latest
    needs: build-wheels
    if: github.event_name == 'push' && startsWith(github.ref, 'refs/tags/v')
    steps:
      - uses: actions/download-artifact@v4
        with:
          path: ./artifacts
      - uses: softprops/action-gh-release@v2
        with:
          name: Release ${{ github.ref_name }}
          files: |
            ./artifacts/wheel-ubuntu-latest/*.whl
            ./artifacts/wheel-windows-latest/*.whl
            ./artifacts/wheel-macos-latest/*.whl
          overwrite: true
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

  deploy-demo-model:
    name: 🚀 Deploy & Validate Demo Model
    runs-on: ubuntu-latest
    needs: release
    steps:
      - run: echo "${{ secrets.GHCR_PAT }}" | docker login ghcr.io -u ${{ github.actor }} --password-stdin
      - run: |
          docker run -d --gpus all --name mlc-server -p 8000:8000 \
            ghcr.io/${{ github.repository }}:latest \
            bash -c "
              mlc_llm download-model --model-name Llama-2-7b-chat-hf-q4f16_1 && \
              mlc_llm serve --model Llama-2-7b-chat-hf-q4f16_1
            "
      - run: |
          for i in {1..15}; do
            curl -fsS http://localhost:8000/ && exit 0
            sleep 5
          done
          echo "Health check failed" >&2
          exit 1
      - run: |
          curl -X POST http://localhost:8000/v1/chat/completions \
            -H "Content-Type: application/json" \
            -d '{
              "model": "Llama-2-7b-chat-hf-q4f16_1",
              "messages": [{"role": "user", "content": "Hello, who are you?"}]
            }' | jq .
      - run: docker rm -f mlc-server
        if: always()

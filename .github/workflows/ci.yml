name: MLC-LLM CI/CD

on:
  push:
    branches: [ main ]
    tags: [ 'v*.*.*' ]
  pull_request:
    branches: [ main ]
  workflow_dispatch:

permissions:
  contents: write

defaults:
  run:
    shell: bash
    working-directory: .

jobs:

  # Stage 1: Build and Push Docker Image to GHCR
  docker-build:
    name: Build Docker Image
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: docker/setup-qemu-action@v3
      - uses: docker/setup-buildx-action@v3
      - uses: docker/login-action@v3
        with:
          registry: ghcr.io
          username: ${{ github.actor }}
          password: ${{ secrets.GHCR_PAT }}
      - uses: docker/build-push-action@v5
        with:
          context: .
          file: docker/Dockerfile
          push: true
          tags: ghcr.io/${{ github.repository }}:latest
          platforms: linux/amd64

  # Stage 2: Run Automated Tests inside Docker
  test:
    name: Run Automated Tests
    runs-on: ubuntu-latest
    needs: docker-build
    steps:
      - uses: actions/checkout@v4
      - run: echo "${{ secrets.GHCR_PAT }}" | docker login ghcr.io -u ${{ github.actor }} --password-stdin
      - run: |
          docker run --rm \
            -e CI=true \
            -v ${{ github.workspace }}:/workspace \
            -w /workspace \
            ghcr.io/${{ github.repository }}:latest \
            ./scripts/test-image.sh

  # Stage 3: Build Python Wheels for Linux, Windows, macOS
  build-wheels:
    name: Build Python Wheels
    runs-on: ${{ matrix.os }}
    needs: test
    strategy:
      matrix:
        os: [ubuntu-latest, windows-latest, macos-latest]
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with:
          python-version: '3.10'
      - uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}
      - run: pip install build
      - run: python -m build python/
      - name: Rename wheel to include platform
        run: |
          WHEEL=$(ls python/dist/*.whl)
          PLATFORM=$(echo "${{ matrix.os }}" | cut -d'-' -f1)
          VERSION=$(python -c "import importlib.metadata; print(importlib.metadata.version('mlc-llm'))" || echo "0.1.0")
          mv "$WHEEL" "python/dist/mlc_llm-${VERSION}-${PLATFORM}.whl"
      - uses: actions/upload-artifact@v4
        with:
          name: wheel-${{ matrix.os }}
          path: python/dist/*.whl

  # Stage 4: Create GitHub Release
  release:
    name: Create GitHub Release
    runs-on: ubuntu-latest
    needs: build-wheels
    if: github.event_name == 'push' && startsWith(github.ref, 'refs/tags/v')
    steps:
      - uses: actions/download-artifact@v4
        with:
          path: ./artifacts
          pattern: wheel-*
          merge-multiple: true

      - name: Get Version from Tag
        run: |
          echo "VERSION=${GITHUB_REF#refs/tags/v}" >> $GITHUB_ENV

      - uses: softprops/action-gh-release@v2
        with:
          name: Release v${{ env.VERSION }}
          tag_name: v${{ env.VERSION }}
          files: ./artifacts/**/*.whl
          generate_release_notes: true
          overwrite: true
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

  # Stage 5: Deploy and Validate
  deploy-demo-model:
    name: Deploy & Validate Service
    runs-on: ubuntu-latest
    needs: release
    steps:
      - run: echo "${{ secrets.GHCR_PAT }}" | docker login ghcr.io -u ${{ github.actor }} --password-stdin
      - name: Start Demo Server
        run: |
          docker run -d --name mlc-server -p 8000:8000 \
            ghcr.io/${{ github.repository }}:latest \
            bash -c "
              mlc_llm download-model --model-name Llama-2-7b-chat-hf-q4f16_1 && \
              mlc_llm serve --model Llama-2-7b-chat-hf-q4f16_1
            "
      - name: Health Check
        run: |
          for i in {1..15}; do
            curl -fsS http://localhost:8000/ && exit 0
            sleep 5
          done
          echo "Health check failed" >&2
          exit 1
      - name: Test Chat Completion Endpoint
        run: |
          curl -X POST http://localhost:8000/v1/chat/completions \
            -H "Content-Type: application/json" \
            -d '{
              "model": "Llama-2-7b-chat-hf-q4f16_1",
              "messages": [{"role": "user", "content": "Hello, who are you?"}]
            }' | jq .
      - name: Stop Demo Server
        if: always()
        run: docker rm -f mlc-server
